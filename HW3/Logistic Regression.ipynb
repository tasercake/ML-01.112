{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krishna Penukonda\n",
    "\n",
    "1001781"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Part (a)**:\n",
    "\n",
    "> Probabilities lie in the range `[0, 1]`.\n",
    "\n",
    "> In `Equation 1`, we multiply a potentially large number of probabilities, which would result in a vanishingly small value.\n",
    "> Such values either result in inaccuracies or are computationally expensive to represent.\n",
    "\n",
    "> If in its stead we use `Equation 2`, we could use the more computationally efficient addition operation without running into the vanishing value problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b)**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"HW3_data/4/diabetes_train.csv\"\n",
    "TEST_FRACTION = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "def split_xy(data):\n",
    "    return data[:, 1:], data[:, 0]\n",
    "\n",
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Transform labels from [-1, 1] to [0, 1]\n",
    "    \"\"\"\n",
    "    return x, (y + 1) / 2\n",
    "\n",
    "def train_test_split(x, y, fraction=TEST_FRACTION):\n",
    "    assert len(x) == len(y)\n",
    "    split_index = int(len(x) * fraction)\n",
    "    x_train, x_test = x[split_index:], x[:split_index]\n",
    "    y_train, y_test = y[split_index:], y[:split_index]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.finfo(np.float64).eps\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, model_dir=\"model\", save_every=100, plot_every=100):\n",
    "        self.save_every = save_every\n",
    "        self.plot_every = plot_every\n",
    "        self.model_dir = model_dir\n",
    "        os.makedirs(self.model_dir, exist_ok=True)\n",
    "\n",
    "    def concat_ones(self, x):\n",
    "        if len(x.shape) == 1:\n",
    "            concat_shape = (1,)\n",
    "        else:\n",
    "            concat_shape = (len(x), 1)\n",
    "        return np.concatenate((np.ones(concat_shape), x), axis=-1)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        return np.mean(-y_true * np.log(y_pred + eps) - (1 - y_true) * np.log(1 - y_pred + eps))\n",
    "\n",
    "    def fit(self, features, labels, lr=0.01, iterations=1):\n",
    "        ll_history = []\n",
    "\n",
    "        assert len(features) == len(labels)\n",
    "        num_samples = len(features)\n",
    "        features = self.concat_ones(features)  # Add 1 to feature vectors\n",
    "        self.W = np.zeros((features.shape[1])) # Initialize parameters to 0\n",
    "\n",
    "        for i in itertools.count():  # Enables indefinite training by setting `iterations=0`\n",
    "            if iterations and i == iterations:\n",
    "                break\n",
    "            index = np.random.randint(num_samples)\n",
    "            x = features[index]\n",
    "            y_true = labels[index]\n",
    "            y_pred = self.sigmoid(np.dot(x, self.W))\n",
    "            self.W -= lr * x * (y_pred - y_true)\n",
    "\n",
    "            if i % self.save_every == 0:\n",
    "                np.save(f\"model/step_{i}\", self.W)\n",
    "\n",
    "            if i % self.plot_every == 0:\n",
    "                pred = self.sigmoid(np.dot(features, self.W))\n",
    "                ll = self.log_likelihood(pred, labels)\n",
    "                ll_history.append(ll)\n",
    "        print(ll_history)\n",
    "\n",
    "    def transform(self, x):\n",
    "        x = self.concat_ones(x)\n",
    "        return self.sigmoid(np.dot(x, self.W))\n",
    "\n",
    "    def log_likelihood(self, y_pred, y_true):\n",
    "        y_pred = (y_pred * 2) - 1  # Transform back to [-1, 1]\n",
    "        y_true = (y_true * 2) - 1\n",
    "        return np.mean(np.log(1 + np.exp(-y_pred * y_true)), axis=0)\n",
    "\n",
    "    def evaluate(self, features, labels):\n",
    "        y_pred = self.transform(features)\n",
    "        ll = self.log_likelihood(y_pred, labels)\n",
    "        print(\"Log-likelihood:\", ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH, header=None).to_numpy()\n",
    "x, y = split_xy(data)\n",
    "x, y = preprocess(x, y)\n",
    "# x_train, y_train, x_test, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6545493786710933, 0.466740791498438, 0.4576984276623992, 0.46630203355405486, 0.43459230699763657, 0.4208569137046478, 0.41831796469324034, 0.4086740345764076, 0.40442790054076977, 0.4006075919713521, 0.3972036716500872, 0.395617231112861, 0.39087887208642835, 0.38804356095375925, 0.39218414897668635, 0.3837362032872491, 0.38836038092788766, 0.3806740680792935, 0.3873949478607018, 0.38308516588317304, 0.375539954045283, 0.37459486292591737, 0.37340770253506783, 0.37502047769576724, 0.3763889562670835, 0.3728805822011757, 0.37051863903964705, 0.37190924975061324, 0.3696260523603652, 0.36971435082560183, 0.3689531164104237, 0.37258982102242133, 0.37706000926633093, 0.3665356713440492, 0.3670977868762637, 0.3661475436831668, 0.36486031364760346, 0.36548336942042475, 0.3626275800269112, 0.3623443900768206, 0.361206662854668, 0.3608977292999043, 0.36031858427249136, 0.3597017055906214, 0.35993857781454863, 0.35908367042581896, 0.36265119668811596, 0.3585773618679106, 0.35992535757815614, 0.3579827371231805, 0.3579883563396828, 0.35968699488541644, 0.35724911355401007, 0.35583334189594695, 0.3554048844676269, 0.3558162652607754, 0.3566163919729279, 0.3549579606470887, 0.35414746885146176, 0.353924093701611, 0.3552926233366352, 0.35378633561102407, 0.35373759568745183, 0.35412322274272096, 0.35337459205325894, 0.35401391988206327, 0.35762359944536654, 0.35223342092181215, 0.35161666659189134, 0.353580317522255, 0.351478128343146, 0.3510427876193934, 0.350814163799768, 0.3517064580159543, 0.35054471866563647, 0.3502800189762147, 0.35005507861947144, 0.34981967520557083, 0.35058417995619723, 0.35050285511408946, 0.3499419838397877, 0.34923726529878096, 0.3490133347171798, 0.34878960177284324, 0.35007798307629084, 0.3499646057527561, 0.3491956479725789, 0.3482657989366496, 0.34863911337691034, 0.34825317842532666, 0.3479093579517548, 0.3480890096138319, 0.3479736300748006, 0.35024095501079805, 0.34750843993939096, 0.34739746865263466, 0.34749901081106094, 0.35057682011592184, 0.34713420168311754, 0.3469106498024984]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x, y, lr=0.1, iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood: 0.34667505630741235\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
