{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krishna Penukonda\n",
    "\n",
    "1001781"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Part (a)**:\n",
    "\n",
    "> Probabilities lie in the range `[0, 1]`.\n",
    "\n",
    "> In `Equation 1`, we multiply a potentially large number of probabilities, which would result in a vanishingly small value.\n",
    "> Such values either result in inaccuracies or are computationally expensive to represent.\n",
    "\n",
    "> If in its stead we use `Equation 2`, we could use the more computationally efficient addition operation without running into the vanishing value problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b)**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"HW3_data/4/diabetes_train.csv\"\n",
    "TEST_FRACTION = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "def split_xy(data):\n",
    "    return data[:, 1:], data[:, 0]\n",
    "\n",
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Transform labels from [-1, 1] to [0, 1]\n",
    "    \"\"\"\n",
    "    return x, (y + 1) / 2\n",
    "\n",
    "def train_test_split(x, y, fraction=TEST_FRACTION):\n",
    "    assert len(x) == len(y)\n",
    "    split_index = int(len(x) * fraction)\n",
    "    x_train, x_test = x[split_index:], x[:split_index]\n",
    "    y_train, y_test = y[split_index:], y[:split_index]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.finfo(np.float64).eps\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, model_dir=\"model\", save_every=100, plot_every=100):\n",
    "        self.save_every = save_every\n",
    "        self.plot_every = plot_every\n",
    "        self.model_dir = model_dir\n",
    "        os.makedirs(self.model_dir, exist_ok=True)\n",
    "\n",
    "    def concat_ones(self, x):\n",
    "        if len(x.shape) == 1:\n",
    "            concat_shape = (1,)\n",
    "        else:\n",
    "            concat_shape = (len(x), 1)\n",
    "        return np.concatenate((np.ones(concat_shape), x), axis=-1)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        return np.mean(-y_true * np.log(y_pred + eps) - (1 - y_true) * np.log(1 - y_pred + eps))\n",
    "\n",
    "    def fit(self, features, labels, lr=0.01, iterations=1):\n",
    "        ll_history = []\n",
    "\n",
    "        assert len(features) == len(labels)\n",
    "        num_samples = len(features)\n",
    "        features = self.concat_ones(features)  # Add 1 to feature vectors\n",
    "        self.W = np.zeros((features.shape[1])) # Initialize parameters to 0\n",
    "\n",
    "        for i in itertools.count():  # Enables indefinite training by setting `iterations=0`\n",
    "            if iterations and i == iterations:\n",
    "                break\n",
    "            index = np.random.randint(num_samples)\n",
    "            x = features[index]\n",
    "            y_true = labels[index]\n",
    "            y_pred = self.sigmoid(np.dot(x, self.W))\n",
    "            self.W -= lr * x * (y_pred - y_true)\n",
    "\n",
    "            if i % self.save_every == 0:\n",
    "                np.save(f\"model/step_{i}\", self.W)\n",
    "\n",
    "            if i % self.plot_every == 0:\n",
    "                pred = self.sigmoid(np.dot(features, self.W))\n",
    "                ll = self.log_likelihood(pred, labels)\n",
    "                ll_history.append(ll)\n",
    "        print(ll_history)\n",
    "\n",
    "    def transform(self, x):\n",
    "        x = self.concat_ones(x)\n",
    "        return self.sigmoid(np.dot(x, self.W))\n",
    "\n",
    "    def log_likelihood(self, y_pred, y_true):\n",
    "        y_pred = (y_pred * 2) - 1  # Transform back to [-1, 1]\n",
    "        y_true = (y_true * 2) - 1\n",
    "        return np.mean(np.log(1 + np.exp(-y_pred * y_true)), axis=0)\n",
    "\n",
    "    def evaluate(self, features, labels):\n",
    "        y_pred = self.transform(features)\n",
    "        ll = self.log_likelihood(y_pred, labels)\n",
    "        print(\"Log-likelihood:\", ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH, header=None).to_numpy()\n",
    "x, y = split_xy(data)\n",
    "x, y = preprocess(x, y)\n",
    "# x_train, y_train, x_test, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.653005583448345, 0.46760202123116495, 0.4580056293841321, 0.4447249559618966, 0.4384119320620811, 0.43260983367391465, 0.4173450341537369, 0.4109152829713283, 0.4185961138181349, 0.4024096988054098, 0.39713463590392833, 0.3994667357295151, 0.39421654329572264, 0.38946214455806233, 0.38989212936234285, 0.38526858827054095, 0.38496450554800016, 0.3814532418261249, 0.3805576766849137, 0.3782266599531407, 0.378093253118003, 0.37526367310082914, 0.37404671606175394, 0.37373290721171604, 0.37427073171866276, 0.37152014251025645, 0.3705441095819804, 0.3739383345252063, 0.36898671411456674, 0.3681464291733534, 0.3668170924107653, 0.3692723416792016, 0.36541091767783745, 0.3687280108825226, 0.36974698136184814, 0.36761237893139653, 0.36397603183062466, 0.36378351154403527, 0.36361339624419814, 0.36277448284485203, 0.36167267580269147, 0.36292867081528973, 0.36399925674010153, 0.3617391398945139, 0.3604947198669986, 0.36112871812817426, 0.36049961414629994, 0.359359490787791, 0.35907769091413333, 0.3584568898789139, 0.35770074930617934, 0.3573987727023449, 0.35789504101836384, 0.35723448657768175, 0.35796289914079926, 0.3569259791410867, 0.35958198419757853, 0.35694713749036355, 0.35753235460018634, 0.35518394337425974, 0.35564617611162125, 0.3543616215972575, 0.3539895692410568, 0.35347039894899696, 0.3543661294537673, 0.3590370982844509, 0.35382195754516715, 0.3521621102856781, 0.35191919555935236, 0.35183844516354695, 0.3519475469303564, 0.35301846153344907, 0.35323988797435907, 0.352255406398859, 0.3528421221854796, 0.3514882333564927, 0.3505424808892849, 0.3504964692542103, 0.35037702628253525, 0.3529782972759987, 0.35057746648389804, 0.35054670396975285, 0.34983728283244175, 0.34949422771865635, 0.3491398714431957, 0.3497254273233182, 0.3497863501420964, 0.3502762455522528, 0.34875793937878297, 0.3490463972063341, 0.35020235295546936, 0.34813340166197954, 0.34791971528225063, 0.34766751264266893, 0.34794453633766526, 0.3474467323468648, 0.34823268330307805, 0.34893694779468387, 0.35006226587307476, 0.346866413088098]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x, y, lr=0.1, iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood: 0.34667505630741235\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
